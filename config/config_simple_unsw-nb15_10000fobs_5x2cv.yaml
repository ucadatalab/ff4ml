#
# FF4ML simple configuration file
#

# UNSW-NB15
dataset:
  name: unsw-nb15
# Dataset labels and ids
labels:
  - label_background
  - label_dos
  #- label_backdoor
  - label_exploit
  - label_fuzzer
  - label_generic
  - label_reconnaissance
  #- label_shellcode
  #- label_worm
  #- label_analysis

# Class distribution - We remote classes accordingly
#label_generic           3806
#label_background        3549
#label_exploit           1680
#label_fuzzer             714
#label_reconnaissance     147
#label_dos                102
#label_analysis             1
#label_backdoor             1

# Root folders
folder_paths:
  root_path: '../data/unsw-nb15/dat_batches/'
  root_path_output: '../results/'

# Data paths
file_paths:
  mc_file: 'output-NB15_all_extended_10000fobs_254bsize_multiclass.csv'
  mcfold_file: 'output-NB15_all_extended_10000fobs_254bsize_multiclass_folds_5x2cv.csv'
  mcvars_file: 'output-NB15_all_extended_10000fobs_254bsize_multiclass_folds_selecvars_5x2cv.csv'

# Bayesian based hyper-parameter selection
hyper_bayesian:
  # This is the number of different sets of parameters chosen from the search space evaluated
  n_iter: 30
  n_jobs: 16
  cv: 5
  # How many of the above set of parameters are going to be executed in parallel?
  # Each set is evaluated in a k-fold cross-validation process so n_points X cv = n_jobs
  n_points: 3
  # see https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules
  scoring: 'f1_macro'
  random_state: 0
  # Verbosity level, 0 means no verbosity
  verbose: 3

# Model's configuration
models:
  svc:
    hyperparameters:
      C:
        - 0.1
        - 10
      gamma:
        - 0.125
        - 2
      kernel: 'linear'

    general:
      random_state: 0
      verbose: 0

  rf:
    parameters:
      n_estimators:
        - 500 # low value
        - 600 # high value
      max_features:
        - 2 # low value
        - 16 # high value
    general:
      random_state: 0
      n_jobs: 2
      verbose: 0

  lr:
    random_state: 0
    penalty: 'none'
    multi_class: 'auto'
    solver: 'lbfgs'
    verbose: 0

# Multiclass technique
multiclass:
  ovr:
    # -1 means use all available computing cores
    n_jobs: -1
